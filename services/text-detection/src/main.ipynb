{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0e3062",
   "metadata": {},
   "source": [
    "## Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e145dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from craft_text_detector import craft_utils, file_utils\n",
    "from craft_text_detector import imgproc\n",
    "from craft_text_detector.craft import CRAFT\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57268d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2547d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c0f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, image, text_threshold, link_threshold, low_text, poly, refine_net=None):\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "\n",
    "    return boxes, polys, ret_score_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ddbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esaak/my_folder/CProjects/vk/Image-description-generation/services/text-detection/vk_summer/lib64/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/esaak/my_folder/CProjects/vk/Image-description-generation/services/text-detection/vk_summer/lib64/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CRAFT model from: ./models/craft_ic15_20k.pth\n",
      "CRAFT model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "image_path = './data/'\n",
    "model_path = './models/' + 'craft_ic15_20k.pth'\n",
    "text_threshold = 0.7\n",
    "link_threshold=0.4\n",
    "low_text =0.4\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "822e4428",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_size = 1280\n",
    "mag_ratio = 1.5\n",
    "poly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "116be19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list, _, _ = file_utils.get_files(image_path)\n",
    "result_folder = './result/'\n",
    "if not os.path.isdir(result_folder):\n",
    "    os.mkdir(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esaak/my_folder/CProjects/vk/Image-description-generation/services/text-detection/vk_summer/lib64/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/esaak/my_folder/CProjects/vk/Image-description-generation/services/text-detection/vk_summer/lib64/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (./models/craft_ic15_20k.pth)\n",
      "Test image 17/17: ./data/test18.jpgg\r"
     ]
    }
   ],
   "source": [
    "net = CRAFT()     # initialize\n",
    "\n",
    "print('Loading weights from checkpoint (' + model_path + ')')\n",
    "net.load_state_dict(copyStateDict(torch.load(model_path, map_location=device)))\n",
    "net.eval()\n",
    "\n",
    "\n",
    "\n",
    "# load data\n",
    "for k, image_path in enumerate(image_list):\n",
    "    print(\"Test image {:d}/{:d}: {:s}\".format(k+1, len(image_list), image_path), end='\\r')\n",
    "    image = imgproc.loadImage(image_path)\n",
    "\n",
    "    bboxes, polys, score_text = test_net(net, image, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # save score text\n",
    "    filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "    mask_file = result_folder + \"/res_\" + filename + '_mask.jpg'\n",
    "    cv2.imwrite(mask_file, score_text)\n",
    "\n",
    "    file_utils.saveResult(image_path, image[:,:,::-1], polys, dirname=result_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vk_summer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
